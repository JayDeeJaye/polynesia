{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to bring it all together.\n",
    "\n",
    "The experiment combines training and testing, so we'll need to get all of this into one loop. Without going too crazy, lets factor the pieces into methods.\n",
    "\n",
    "I don't want to bother with passing Q, N, and other common data structures back and forth through argument lists, so I'm going to use global scope and not worry about it.\n",
    "\n",
    "Here's the algorithm I'm shooting for:\n",
    "\n",
    "```\n",
    "Set learning rate, discount, and epsilon for the experiment\n",
    "For each run\n",
    "    Initialize environment\n",
    "    while training runs < some number\n",
    "        train the agent\n",
    "        reset players\n",
    "        test the agent\n",
    "        capture x = N, p1 reward, p2 reward, p3 reward\n",
    "        increase N\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load global_identifiers.py\n",
    "# Global identifiers\n",
    "from collections import defaultdict\n",
    "\n",
    "ACTIONS=('HIT','STAND',)\n",
    "\n",
    "# Learning functions\n",
    "Q = defaultdict(float)\n",
    "N = defaultdict(float)\n",
    "\n",
    "# Learning variables\n",
    "epsilon = 10\n",
    "lr = 0.08\n",
    "discount = 0.99\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic strategy loaded into BASIC\n"
     ]
    }
   ],
   "source": [
    "# %load load_strategy.py\n",
    "import csv\n",
    "\n",
    "BASIC = {}\n",
    "f = open('BasicStrategy_1.csv','r')\n",
    "reader = csv.reader(f)\n",
    "for line in reader:\n",
    "    BASIC[(int(line[0]),int(line[1]))] = line[2]\n",
    "f.close()\n",
    "\n",
    "print(\"Basic strategy loaded into BASIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load training.py\n",
    "import logging\n",
    "import random\n",
    "from utilities import *\n",
    "#from global_identifiers import *\n",
    "\n",
    "#\n",
    "# Global references:\n",
    "# N - the state-action counter for greedy-epsilon exploration function\n",
    "# Q - the Q(s,a) function\n",
    "# epsilon, lr, discount\n",
    "\n",
    "# Get an action using exploration/exploitation based in the current state\n",
    "def getTrainAction(s):\n",
    "    global Q\n",
    "    e = epsilon/(epsilon + N[s])\n",
    "    rr = random.random()\n",
    "    if rr < e:\n",
    "        logging.debug(\"Exploring (N[s] = {}, e = {}, rr = {}): Random action selected\".format(N[s],e,rr))\n",
    "        return ACTIONS[random.randint(0,1)]\n",
    "    else:\n",
    "        # Use what we've learned\n",
    "        logging.debug(\"Exploiting (N[s] = {}, e = {}, rr = {}): Optimal action selected\".format(N[s],e,rr))\n",
    "        if Q[s+('HIT',)] > Q[s+('STAND',)]:\n",
    "            return 'HIT'\n",
    "        else:\n",
    "            return 'STAND'\n",
    "\n",
    "# Updated Q(s,a) value\n",
    "def getUpdatedQsa(sa,r,s1):\n",
    "    global Q\n",
    "    logging.debug(\"Updating Q{} {} ...\".format(sa,Q[sa]))\n",
    "    q = Q[sa] + 0.08*(r + discount*max(Q[s1+ACTIONS[0:1]],Q[s1+ACTIONS[1:2]]) - Q[sa])\n",
    "    logging.debug(\"Updated Q{} {} ...\".format(sa,q))\n",
    "    return q\n",
    "\n",
    "\n",
    "def trainQLAgent(dealer,players,shoe,n):\n",
    "    global Q, N\n",
    "    # Train with a number of hands\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    pushes = 0\n",
    "\n",
    "    # print(\"Starting bankroll: {}\".format(bankroll))\n",
    "    # Training\n",
    "    for i in range(n):\n",
    "        # New episode\n",
    "        logging.debug(\"==== Episode {} ====\".format(i))\n",
    "        newHand([dealer]+players,shoe)\n",
    "        logging.debug(\"Dealer's hand: {} ({})\".format(dealer.hand,dealer.getPoints()))\n",
    "\n",
    "        for p in players:\n",
    "            logging.debug(\"{}'s hand: {} ({})\".format(p.name,p.hand,p.getPoints()))\n",
    "            p.lastState = (p.getPoints(),dealer.hand[0],)\n",
    "            done = False\n",
    "            while not done:\n",
    "                s = p.lastState\n",
    "\n",
    "                # choose an action\n",
    "                logging.debug(\"Current state: {}\".format(s))\n",
    "                a = getTrainAction(s)\n",
    "                logging.debug(\"{} {}: \".format(p.name,a))\n",
    "\n",
    "                # Take the action\n",
    "                if a == 'HIT':\n",
    "                    hit(p,shoe)\n",
    "                    if p.getPoints() > 21:\n",
    "                        done = True\n",
    "                else:\n",
    "                    done = True\n",
    "\n",
    "                # Update the intermediary Q(s,a)\n",
    "                if not done:\n",
    "                    r = 0\n",
    "                    s1 = (p.getPoints(),dealer.hand[0],)\n",
    "\n",
    "                    # Update Q(s,a)\n",
    "                    Q[s+(a,)] = getUpdatedQsa(s+(a,),r,s1)\n",
    "                    N[s] += 1\n",
    "                    p.lastState = s1\n",
    "                    p.lastAction = a\n",
    "\n",
    "                # This player has reached her terminal state\n",
    "\n",
    "        # All players stand or busted; play out the dealer\n",
    "        while dealer.getPoints() < 17:\n",
    "            logging.debug(\"Dealer HIT: \")\n",
    "            hit(dealer,shoe)\n",
    "        logging.debug(\"Dealer STAND: \")\n",
    "\n",
    "        # Update final Q(s,a)\n",
    "        for p in players:\n",
    "            r = getReward(p,dealer)\n",
    "            s = p.lastState\n",
    "            s1 = (p.getPoints(),dealer.hand[0],)\n",
    "            Q[s+(a,)] = getUpdatedQsa(s+(a,),r,s1)\n",
    "            N[s] += 1\n",
    "\n",
    "            # Metrics\n",
    "            if r < 0:\n",
    "                logging.debug(\"Lose ({})\".format(r))\n",
    "                losses += 1\n",
    "            elif r > 0:\n",
    "                logging.debug(\"Win ({})\".format(r))\n",
    "                wins += 1\n",
    "            else:\n",
    "                logging.debug(\"Push ({})\".format(r))\n",
    "                pushes += 1\n",
    "\n",
    "    print(\"\\n\\tWins: {} %\".format(100*(wins/(wins+losses+pushes))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load playing.py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "#from IPython.core.debugger import Pdb\n",
    "#pdb = Pdb()\n",
    "#pdb.set_trace()\n",
    "\n",
    "#import logging\n",
    "#logger = logging.getLogger()\n",
    "#fhandler = logging.FileHandler(filename='Playing.log', mode='w')\n",
    "#formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "#fhandler.setFormatter(formatter)\n",
    "#logger.addHandler(fhandler)\n",
    "#logger.setLevel(logging.INFO)\n",
    "\n",
    "def testQLAgent(dealer,players,shoe,n):\n",
    "    # Play hands for all players simultaneously\n",
    "\n",
    "    for i in range(n):\n",
    "        # Initialize s\n",
    "        newHand([dealer]+players,shoe)\n",
    "        logging.debug(\"Dealer's hand: {} ({})\".format(dealer.hand,dealer.getPoints()))\n",
    "        # All players play in turn. Rewards are calculated at the end of the hand\n",
    "        for p in players:\n",
    "            logging.debug(\"{}'s hand: {} ({})\".format(p.name,p.hand,p.getPoints()))\n",
    "\n",
    "            while True:\n",
    "                s = (p.getPoints(),dealer.hand[0],)\n",
    "                a = p.getAction(s)\n",
    "                logging.debug(\"{} {}: \".format(p.name,a))\n",
    "\n",
    "                if a == 'HIT':\n",
    "                    hit(p,shoe)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "                if p.getPoints() > 21:\n",
    "                    break\n",
    "\n",
    "        # Players done; play out the dealer\n",
    "        while dealer.getPoints() < 17:\n",
    "            logging.debug(\"Dealer HIT: \")\n",
    "            hit(dealer,shoe)\n",
    "\n",
    "        for p in players:\n",
    "            r = getReward(p,dealer)*5\n",
    "\n",
    "            # Calculate and keep track of wins/losses\n",
    "            if r < 0:\n",
    "                logging.debug(\"Lose ({})\".format(r))\n",
    "                p.losses += 1\n",
    "            elif r > 0:\n",
    "                logging.debug(\"Win ({})\".format(r))\n",
    "                p.wins += 1\n",
    "            else:\n",
    "                logging.debug(\"Push ({})\".format(r))\n",
    "                p.pushes += 1\n",
    "\n",
    "            # Data from the episode    \n",
    "            p.bankRoll += r\n",
    "            p.cumReward.append(p.cumReward[-1]+r)\n",
    "            p.wallet.append(p.bankRoll)\n",
    "\n",
    "    print(\"Results over {} hands:\".format(n))\n",
    "    fig, ax = plt.subplots()\n",
    "    for p in players:\n",
    "        print(\"\\n\\t{} Wins: {} %\\n\\tOutcome: {}\".format(p.name,100*(p.wins/(p.wins+p.losses+p.pushes)),p.bankRoll))\n",
    "        ax.plot(p.cumReward,label=p.name)\n",
    "\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "#fig = plt.figure(1,figsize=(12,6))\n",
    "\n",
    "#plt.subplot(121)\n",
    "#plt.plot(CR)\n",
    "#plt.title('Cumulative reward for {} hands'.format(n))\n",
    "\n",
    "#plt.subplot(122)\n",
    "#plt.plot(WALLET)\n",
    "#plt.title('Bankroll over {} hands assuming $5 bet'.format(n))\n",
    "\n",
    "#fig.tight_layout()\n",
    "#logger.removeHandler(fhandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tWins: 29.447499999999998 %\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eaed3d7087ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtestingPlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000.00\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtestQLAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestingPlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshoe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#logger.removeHandler(fhandler)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-57962adbce04>\u001b[0m in \u001b[0;36mtestQLAgent\u001b[0;34m(dealer, players, shoe, n)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdealer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} {}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julie/CSC581/project/polynesia/player.py\u001b[0m in \u001b[0;36mgetAction\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mqas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Q' is not defined"
     ]
    }
   ],
   "source": [
    "# %load main.py\n",
    "from player import *\n",
    "from shoe import Shoe\n",
    "#from utilities import *\n",
    "from collections import defaultdict\n",
    "\n",
    "#import logging\n",
    "#logger = logging.getLogger()\n",
    "#fhandler = logging.FileHandler(filename='Experiment.log', mode='a')\n",
    "#formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "#fhandler.setFormatter(formatter)\n",
    "#logger.addHandler(fhandler)\n",
    "#logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Global identifiers\n",
    "#global Q, N, epsilon, lr, discount\n",
    "\n",
    "# Game setup\n",
    "shoe = Shoe(1)\n",
    "dealer = Player(\"Dealer\")\n",
    "\n",
    "# Learning functions\n",
    "Q = defaultdict(float)\n",
    "N = defaultdict(float)\n",
    "\n",
    "# Learning variables\n",
    "epsilon = 10\n",
    "lr = 0.08\n",
    "discount = 0.99\n",
    "\n",
    "trainingPlayers = [Player(\"Player 1\")]\n",
    "trainingPlayers.append(Player(\"Player 2\"))\n",
    "trainingPlayers.append(Player(\"Player 3\"))\n",
    "trainingPlayers.append(Player(\"Player 4\"))\n",
    "\n",
    "trainQLAgent(dealer,trainingPlayers,shoe,10000)\n",
    "\n",
    "testingPlayers = []\n",
    "testingPlayers.append(QPolicyPlayer(\"Q Player\",1000.00))\n",
    "testingPlayers.append(OPolicyPlayer(\"Basic Player\",1000.00))\n",
    "testingPlayers.append(Player(\"Random\",1000.00))\n",
    "\n",
    "testQLAgent(dealer,testingPlayers,shoe,1000)\n",
    "\n",
    "#logger.removeHandler(fhandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
