{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 4, we went further in training the model to play with two actions. We have an optimal policy saved from the Basic Strategy for 1 deck found on Wizard of Odds, adjusted to just HIT and STAND actions -- without splitting or doubling down.\n",
    "\n",
    "We tried to measure the performance of the training algorithm by itself, by using culumative reward, discounted reward-to-go, RMS of the policy to see if it changed much over time, etc. Nothing was really definitive, although seeing (what I think is) discounted reward-to-go flatten out over time was encouraging; plus, it flattened out on the negative side, so it showed that the generated policy is definitely not a winner. We showed that anyway in Part 3.\n",
    "\n",
    "The best measurement of success is probably going to be playing with the caclculated model.\n",
    "\n",
    "Let's refactor what we have and expand it.\n",
    "* Create a new method for getAction in the Player class. This correlates to the strategy a player will take after training is over. By default, it's random action\n",
    "* Create two subclasses for Player: QPolicyPlayer, and OPolicyPlayer, for players who will follow the Q(s,a) policy and the basic strategy respectively.\n",
    "* Move metrics into the Player class\n",
    "* Add multi-players to the training loop. Goal: 3\n",
    "    * Put last state, action into Player class\n",
    "* Design runs strategy to average results\n",
    "\n",
    "Nice to have\n",
    "* Create a class for policies? Right now, they're global variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utilities.py\n"
     ]
    }
   ],
   "source": [
    "# %load utilities.py\n",
    "import random\n",
    "import logging\n",
    "\n",
    "def hit(p,s):\n",
    "    p.receive(s.draw())\n",
    "    logging.debug(\"New hand: {} ({})\".format(p.hand,p.getPoints()))\n",
    "\n",
    "def newHand(P,s):\n",
    "    for p in P:\n",
    "        p.reset()\n",
    "    deal(P,s)\n",
    "\n",
    "# Deal\n",
    "def deal(P,s):\n",
    "    for i in range(2):\n",
    "        for p in P:\n",
    "            p.receive(s.draw())\n",
    "    \n",
    "# Updated getAction() using exploration/exploitation\n",
    "def getTrainAction(Q,N,s):\n",
    "    e = epsilon/(epsilon + N[s])\n",
    "    rr = random.random()\n",
    "    if rr < e:\n",
    "        logging.debug(\"Exploring (N[s] = {}, e = {}, rr = {}): Random action selected\".format(N[s],e,rr))\n",
    "        return ACTIONS[random.randint(0,1)]\n",
    "    else:\n",
    "        # Use what we've learned\n",
    "        logging.debug(\"Exploiting (N[s] = {}, e = {}, rr = {}): Optimal action selected\".format(N[s],e,rr))\n",
    "        if Q[s+('HIT',)] > Q[s+('STAND',)]:\n",
    "            return 'HIT'\n",
    "        else:\n",
    "            return 'STAND'\n",
    "\n",
    "# Updated Q(s,a) value\n",
    "def getUpdatedQsa(Q,sa,r,s1,A):\n",
    "    logging.debug(\"Updating Q{} {} ...\".format(sa,Q[sa]))\n",
    "    q = Q[sa] + 0.08*(r + discount*max(Q[s1+A[0:1]],Q[s1+A[1:2]]) - Q[sa])\n",
    "    logging.debug(\"Updated Q{} {} ...\".format(sa,q))\n",
    "    return q\n",
    "\n",
    "def getReward(p,d):\n",
    "    if p.getPoints() > 21:\n",
    "        return -1\n",
    "\n",
    "    # Blackjack?\n",
    "    if d.hasBlackjack():\n",
    "        if p.hasBlackjack():\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    elif p.hasBlackjack():\n",
    "        return 1.5\n",
    "    elif d.getPoints() > 21:\n",
    "        return 1\n",
    "    elif p.getPoints() > d.getPoints():\n",
    "        return 1\n",
    "    elif p.getPoints() == d.getPoints():\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting player.py\n"
     ]
    }
   ],
   "source": [
    "# %load player.py\n",
    "# Player class\n",
    "import random\n",
    "\n",
    "ACTIONS = ['HIT','STAND']\n",
    "\n",
    "class Player:\n",
    "    def __init__(self,name,bankRoll=0):\n",
    "        self.name = name\n",
    "        self.bankRoll = bankRoll\n",
    "        self.wallet = []\n",
    "        self.wins = 0\n",
    "        self.losses = 0\n",
    "        self.pushes = 0\n",
    "        self.cumReward = [0]\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.hand = []\n",
    "        self.lastState = ()\n",
    "        self.lastAction = ''\n",
    "        \n",
    "    def receive(self,card):\n",
    "        self.hand += [card]\n",
    "        \n",
    "    def getPoints(self):\n",
    "        points = sum(self.hand)\n",
    "        if points <= 21:\n",
    "            return points\n",
    "\n",
    "        while (points > 21) and (11 in self.hand):\n",
    "            self.hand[self.hand.index(11)] = 1\n",
    "            points = sum(self.hand)\n",
    "\n",
    "        return points\n",
    "    \n",
    "    def hasBlackjack(self):\n",
    "        return (self.getPoints() == 21 and len(self.hand) == 2)\n",
    "    \n",
    "    # Default action for a player is random\n",
    "    def getAction(self,_):\n",
    "        return ACTIONS[random.randint(0,len(ACTIONS)-1)]\n",
    "\n",
    "class QPolicyPlayer(Player):\n",
    "    def getAction(self,s):\n",
    "        qas = {q: Q[q] for q in Q.keys() if q[0:2] == s}\n",
    "        sa = max(qas.keys(), key=lambda k: qas[k])\n",
    "        return sa[-1]\n",
    "    \n",
    "class OPolicyPlayer(Player):\n",
    "    def getAction(self,s):\n",
    "        return BASIC[s]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting load_strategy.py\n"
     ]
    }
   ],
   "source": [
    "# %load load_strategy.py\n",
    "import csv\n",
    "\n",
    "BASIC = {}\n",
    "f = open('BasicStrategy_1.csv','r')\n",
    "reader = csv.reader(f)\n",
    "for line in reader:\n",
    "    BASIC[(int(line[0]),int(line[1]))] = line[2]\n",
    "f.close()\n",
    "\n",
    "print(\"Basic strategy loaded into BASIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "# %load main.py\n",
    "#from player import Player\n",
    "from shoe import Shoe\n",
    "#from utilities import hit, newHand, deal, getReward, getAction, getUpdatedQsa\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#import logging\n",
    "#logger = logging.getLogger()\n",
    "#fhandler = logging.FileHandler(filename='Training.log', mode='a')\n",
    "#formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "#fhandler.setFormatter(formatter)\n",
    "#logger.addHandler(fhandler)\n",
    "#logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Initialize\n",
    "# Game elements\n",
    "shoe = Shoe(1)\n",
    "dealer = Player(\"Dealer\")\n",
    "players = [Player(\"Player 1\")]\n",
    "players.append(Player(\"Player 2\"))\n",
    "\n",
    "ACTIONS=('HIT','STAND',)\n",
    "\n",
    "# Learning functions\n",
    "Q = defaultdict(float)\n",
    "N = defaultdict(float)\n",
    "\n",
    "# Learning variables\n",
    "epsilon = 10\n",
    "lr = 0.08\n",
    "discount = 0.99\n",
    "\n",
    "#logger.removeHandler(fhandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training.py\n"
     ]
    }
   ],
   "source": [
    "# %load training.py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='Training.log', mode='w')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Intitalize first!\n",
    "# Train with a number of hands\n",
    "wins = 0\n",
    "losses = 0\n",
    "pushes = 0\n",
    "R=[0]\n",
    "n = 100000\n",
    "\n",
    "# print(\"Starting bankroll: {}\".format(bankroll))\n",
    "# Training\n",
    "for i in range(n):\n",
    "    # New episode\n",
    "    logging.debug(\"==== Episode {} ====\".format(i))\n",
    "    newHand([dealer]+players,shoe)\n",
    "    logging.debug(\"Dealer's hand: {} ({})\".format(dealer.hand,dealer.getPoints()))\n",
    "    \n",
    "    for p in players:\n",
    "        logging.debug(\"{}'s hand: {} ({})\".format(p.name,p.hand,p.getPoints()))\n",
    "        p.lastState = (p.getPoints(),dealer.hand[0],)\n",
    "        done = False\n",
    "        while not done:\n",
    "            s = p.lastState\n",
    "\n",
    "            # choose an action\n",
    "            logging.debug(\"Current state: {}\".format(s))\n",
    "            a = getTrainAction(Q,N,s)\n",
    "            logging.debug(\"{} {}: \".format(p.name,a))\n",
    "\n",
    "            # Take the action\n",
    "            if a == 'HIT':\n",
    "                hit(p,shoe)\n",
    "                if p.getPoints() > 21:\n",
    "                    done = True\n",
    "            else:\n",
    "                done = True\n",
    "\n",
    "            # Update the intermediary Q(s,a)\n",
    "            if not done:\n",
    "                r = 0\n",
    "                s1 = (p.getPoints(),dealer.hand[0],)\n",
    "\n",
    "                # Update Q(s,a)\n",
    "                Q[s+(a,)] = getUpdatedQsa(Q,s+(a,),r,s1,ACTIONS)\n",
    "                N[s] += 1\n",
    "                p.lastState = s1\n",
    "                p.lastAction = a\n",
    "\n",
    "            # This player has reached her terminal state\n",
    "    \n",
    "    # All players stand or busted; play out the dealer\n",
    "    while dealer.getPoints() < 17:\n",
    "        logging.debug(\"Dealer HIT: \")\n",
    "        hit(dealer,shoe)\n",
    "    logging.debug(\"Dealer STAND: \")\n",
    "\n",
    "    # Update final Q(s,a)\n",
    "    for p in players:\n",
    "        r = getReward(p,dealer)\n",
    "        s = p.lastState\n",
    "        s1 = (p.getPoints(),dealer.hand[0],)\n",
    "        Q[s+(a,)] = getUpdatedQsa(Q,s+(a,),r,s1,ACTIONS)\n",
    "        N[s] += 1\n",
    "\n",
    "        # Metrics\n",
    "        if r < 0:\n",
    "            logging.debug(\"Lose ({})\".format(r))\n",
    "            losses += 1\n",
    "        elif r > 0:\n",
    "            logging.debug(\"Win ({})\".format(r))\n",
    "            wins += 1\n",
    "        else:\n",
    "            logging.debug(\"Push ({})\".format(r))\n",
    "            pushes += 1\n",
    "\n",
    "print(\"\\n\\tWins: {} %\".format(100*(wins/(wins+losses+pushes))))\n",
    "\n",
    "logger.removeHandler(fhandler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting playing.py\n"
     ]
    }
   ],
   "source": [
    "# %load playing.py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.core.debugger import Pdb\n",
    "pdb = Pdb()\n",
    "#pdb.set_trace()\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='Playing.log', mode='w')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Intitalize first!\n",
    "# Play 100,000 hands\n",
    "bankroll = 1000.00\n",
    "wins = 0\n",
    "losses = 0\n",
    "pushes = 0\n",
    "WALLET=[]\n",
    "R=[0]\n",
    "n = 1000\n",
    "dealer = Player(\"Dealer\")\n",
    "players=[QPolicyPlayer(\"Q Player\",1000.0)]\n",
    "players.append(OPolicyPlayer(\"Basic Player\",1000.0))\n",
    "players.append(Player(\"Random Player\",1000.0))\n",
    "\n",
    "#player1 = QPolicyPlayer(\"Q-Player\",1000.0)\n",
    "#player2 = OPolicyPlayer(\"BasicPlayer\",1000.0)\n",
    "\n",
    "# Play hands for both players simultaneously\n",
    "\n",
    "for i in range(n):\n",
    "    # Initialize s\n",
    "    newHand([dealer]+players,shoe)\n",
    "    logging.debug(\"Dealer's hand: {} ({})\".format(dealer.hand,dealer.getPoints()))\n",
    "    # All players play in turn. Rewards are calculated at the end of the hand\n",
    "    for p in players:\n",
    "        logging.debug(\"{}'s hand: {} ({})\".format(p.name,p.hand,p.getPoints()))\n",
    "\n",
    "        while True:\n",
    "            s = (p.getPoints(),dealer.hand[0],)\n",
    "            a = p.getAction(s)\n",
    "            logging.debug(\"{} {}: \".format(p.name,a))\n",
    "    \n",
    "            if a == 'HIT':\n",
    "                hit(p,shoe)\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "            if p.getPoints() > 21:\n",
    "                break\n",
    "    \n",
    "    # Players done; play out the dealer\n",
    "    while dealer.getPoints() < 17:\n",
    "        logging.debug(\"Dealer HIT: \")\n",
    "        hit(dealer,shoe)\n",
    "\n",
    "    for p in players:\n",
    "        r = getReward(p,dealer)*5\n",
    "\n",
    "        # Calculate and keep track of wins/losses\n",
    "        if r < 0:\n",
    "            logging.debug(\"Lose ({})\".format(r))\n",
    "            p.losses += 1\n",
    "        elif r > 0:\n",
    "            logging.debug(\"Win ({})\".format(r))\n",
    "            p.wins += 1\n",
    "        else:\n",
    "            logging.debug(\"Push ({})\".format(r))\n",
    "            p.pushes += 1\n",
    "\n",
    "        # Data from the episode    \n",
    "        p.bankRoll += r\n",
    "        p.cumReward.append(p.cumReward[-1]+r)\n",
    "        p.wallet.append(p.bankRoll)\n",
    "\n",
    "print(\"Results over {} hands:\".format(n))\n",
    "fig, ax = plt.subplots()\n",
    "for p in players:\n",
    "    print(\"\\n\\t{} Wins: {} %\\n\\tOutcome: {}\".format(p.name,100*(p.wins/(p.wins+p.losses+p.pushes)),p.bankRoll))\n",
    "    ax.plot(p.cumReward,label=p.name)\n",
    "\n",
    "ax.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#fig = plt.figure(1,figsize=(12,6))\n",
    "\n",
    "#plt.subplot(121)\n",
    "#plt.plot(CR)\n",
    "#plt.title('Cumulative reward for {} hands'.format(n))\n",
    "\n",
    "#plt.subplot(122)\n",
    "#plt.plot(WALLET)\n",
    "#plt.title('Bankroll over {} hands assuming $5 bet'.format(n))\n",
    "\n",
    "#fig.tight_layout()\n",
    "logger.removeHandler(fhandler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
